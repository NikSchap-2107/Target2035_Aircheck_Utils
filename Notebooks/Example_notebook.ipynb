{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94723692",
   "metadata": {},
   "source": [
    "# ðŸš€**Taret 2035 Aircheck DEL-ML example**ðŸ§¬\n",
    "Welcome to the Target 2035 Aircheck DEL-ML Model Training and Prediction example Notebook!\n",
    "\n",
    "This notebook will walk you through the basic steps involved in training, evaluating, and screening small molecules using machine learning models built on chemical fingerprints.\n",
    "\n",
    "**This is a sample workflow that illustrates how selections can be made and compounds clustered based on their chemical diversity. This very simple pipeline is using exclusively the training set, which is not best practice and should not be repeated. The goal is only to provide sample scripts that can be adapted for this challenge.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4722bfeb",
   "metadata": {},
   "source": [
    "## Loading input file\n",
    "\n",
    "Here we use the data in the file *WDR91.parquet* as both training and external test dataset.\n",
    "\n",
    "In an ideal case the external test set should not be selected at random from the existing training data, but here it is done for the sake of simplicity.\n",
    "\n",
    "The file containing the training set file can be downloaded from [Aircheck](https://aircheck.ai/datasets), from the DEL-Datasets, target WDR91, and partner HitGen.\n",
    "\n",
    "The file contains multiple columns containing important data regarding the DEL library and the compounds (BB1_ID, BB2_ID, NTC_VALUE, ENRICHMENT, etc.), the fingerprints used to represent the molecules (ECFP4, ECFP6, FCFP4, FCFP6, TOPTOR, MACCS, RDK, AVALON), and  the label LABEL identifying the molecule as a DEL hit (**1**) or not (**0**).\n",
    "\n",
    "In this notebook only the columns ECFP4 and LABEL are read from the file.\n",
    "\n",
    "To simulate a virtual screening campaign the dataset is split in two:\n",
    "* Training set: used to train the model.\n",
    "* Test set: used to evaluate the performance of the model in a virtual screening-like scenario.\n",
    "\n",
    "**It is not best practice to perform random train-test split on training set data, since similar molecules could be present in both the training and test set, leading to overoptimistic results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a84db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../ReadingParquetFiles\") #Used to import module from different folder in the repository \n",
    "from read_parquet_utils import read_parquet_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "data_file = \"WDR91.parquet\" #Change to the path to your file\n",
    "df = read_parquet_file(data_file, columns = ['ECFP4', 'LABEL'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.ECFP4,\n",
    "                                                    df.LABEL,\n",
    "                                                    test_size=0.10,\n",
    "                                                    random_state=42,\n",
    "                                                    shuffle=True,\n",
    "                                                    stratify=df.LABEL,)\n",
    "x_train = np.stack(x_train)\n",
    "x_test = np.stack(x_test)\n",
    "y_train = y_train.to_numpy(dtype=int)\n",
    "y_test = y_test.to_numpy(dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a24203d",
   "metadata": {},
   "source": [
    "## Model training\n",
    "A random forest classification model was trained on count ECFP4. The model is kept at default hyperparamters except for the number of estimators, reduced from 100 to 10 to speed up calculations.\n",
    "\n",
    "### Cross validation\n",
    "The performance of the trained models are evaluated in 5-fold cross validation.\n",
    "\n",
    "The training set is split in five subsets, five different models are trained using four of the five subsets, while the one not used for training is used for evaluation.\n",
    "\n",
    "Cross validation gives an estimate of the performance of a trained model, before using it on the test set.\n",
    "\n",
    "Here the models are evaluated based on different metrics, with a value of 1 in each of them representing an ideal model:\n",
    "* **Precision**: number of molecules predicted as active which are active.\n",
    "* **Recall**: fraction of active molecules predicted as active.\n",
    "* **F1-score**: harmonic mean of precision and recall.\n",
    "* **AUC-ROC**: measures the ability of the score in prioritizing active molecules (higher scores) against inactive molecules (lower scores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6251b1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Metrics:\n",
      "Precision: 0.8869\n",
      "Recall: 0.6295\n",
      "F1-Score: 0.7364\n",
      "AUC-ROC: 0.9487\n",
      "----------------------------------------\n",
      "Fold 2 Metrics:\n",
      "Precision: 0.8874\n",
      "Recall: 0.6315\n",
      "F1-Score: 0.7379\n",
      "AUC-ROC: 0.9527\n",
      "----------------------------------------\n",
      "Fold 3 Metrics:\n",
      "Precision: 0.8864\n",
      "Recall: 0.6309\n",
      "F1-Score: 0.7371\n",
      "AUC-ROC: 0.9508\n",
      "----------------------------------------\n",
      "Fold 4 Metrics:\n",
      "Precision: 0.8851\n",
      "Recall: 0.6288\n",
      "F1-Score: 0.7352\n",
      "AUC-ROC: 0.9486\n",
      "----------------------------------------\n",
      "Fold 5 Metrics:\n",
      "Precision: 0.8888\n",
      "Recall: 0.6355\n",
      "F1-Score: 0.7411\n",
      "AUC-ROC: 0.9509\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score,roc_auc_score\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle = True, random_state=42)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(x_train, y_train)):\n",
    "    model = RandomForestClassifier(n_estimators=10) #Reduced from the defult 100 to save time\n",
    "    model.fit(x_train[train_index], y_train[train_index])\n",
    "    y_score = model.predict_proba(x_train[test_index])[:,1]\n",
    "    y_pred = model.predict(x_train[test_index])\n",
    "\n",
    "    metrics = {\"Precision\": precision_score(y_train[test_index], y_pred, zero_division=0),\n",
    "                \"Recall\": recall_score(y_train[test_index], y_pred),\n",
    "                \"F1-Score\": f1_score(y_train[test_index], y_pred),\n",
    "                \"AUC-ROC\": roc_auc_score(y_train[test_index], y_score)}\n",
    "\n",
    "    print(f\"Fold {i+1} Metrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7992b452",
   "metadata": {},
   "source": [
    "### Evaluation on the \"external\" test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b17d05c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "External test set Metrics:\n",
      "Precision: 0.8905\n",
      "Recall: 0.6442\n",
      "F1-Score: 0.7476\n",
      "AUC-ROC: 0.9545\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=10).fit(x_train, y_train)\n",
    "y_score = model.predict_proba(x_test)[:,1]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "metrics = {\"Precision\": precision_score(y_test, y_pred, zero_division=0),\n",
    "                \"Recall\": recall_score(y_test, y_pred),\n",
    "                \"F1-Score\": f1_score(y_test, y_pred),\n",
    "                \"AUC-ROC\": roc_auc_score(y_test, y_score)}\n",
    "\n",
    "print(f\"External test set Metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3569f39",
   "metadata": {},
   "source": [
    "### Saving the model\n",
    "The model can be saved as a *pickle* file for future use or for sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1920fb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('Aircheck_WDR91_model.pkl', 'wb') as out:\n",
    "    pickle.dump(model, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f428066",
   "metadata": {},
   "source": [
    "## Molecule selection based on chemical diversity\n",
    "\n",
    "A machine learning model can identify thousands of potentially active molecules in a chemical library, however in drug discovery only a limited number of them can be tested experimentally (10-100 molecules).\n",
    "\n",
    "To better explore the chemical space, high-ranking molecules are often clustered based on molecular similarity to select a smaller number of diverse compounds.\n",
    "\n",
    "Here the top 5000 molecules were clustered based on their Tanimoto similarity (also known as Jaccard similarity/distance) between binary ECFP4 using the agglomerative clustering algorithm, selecting a diverse set of 200 and 500 molecules. From each cluster the molecule with the highest probability score was selected.\n",
    "\n",
    "**Here agglomerative clustering is used as an example, there are other clustering algorithms or diveristy selection methods (eg. Butina clustering, LeaderPicker from the rdkit) which should be considered.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55d9916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "top_5000 = np.argsort(y_score)[-1:-5001:-1]\n",
    "cluster_fp = x_test[top_5000]\n",
    "distance = pdist(cluster_fp != 0, metric = 'jaccard') #Turn the count ECFP4 into binary ECFP4\n",
    "clustering_200 = AgglomerativeClustering(n_clusters=200,\n",
    "                                    metric='precomputed',\n",
    "                                    linkage='complete')\n",
    "cluster_labels_200 = clustering_200.fit_predict(squareform(distance))\n",
    "clustering_500 = AgglomerativeClustering(n_clusters=500,\n",
    "                                    metric='precomputed',\n",
    "                                    linkage='complete')\n",
    "cluster_labels_500 = clustering_500.fit_predict(squareform(distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3166dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numer or hits found in the selected 200 molecules: 133\n",
      "Numer or hits found in the selected 500 molecules: 241\n"
     ]
    }
   ],
   "source": [
    "hits_200 = 0\n",
    "hits_500 = 0\n",
    "seen_cluster_200 = set()\n",
    "seen_cluster_500 = set()\n",
    "for sorted_index, original_index in enumerate(top_5000):\n",
    "    if cluster_labels_200[sorted_index] not in seen_cluster_200:\n",
    "        seen_cluster_200.add(cluster_labels_200[sorted_index])\n",
    "        if y_test[original_index]:\n",
    "            hits_200 += 1\n",
    "    if cluster_labels_500[sorted_index] not in seen_cluster_500:\n",
    "        seen_cluster_500.add(cluster_labels_500[sorted_index])\n",
    "        if y_test[original_index]:\n",
    "            hits_500 += 1\n",
    "print(f\"Numer or hits found in the selected 200 molecules: {hits_200}\")\n",
    "print(f\"Numer or hits found in the selected 500 molecules: {hits_500}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genbench3d_Luca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
